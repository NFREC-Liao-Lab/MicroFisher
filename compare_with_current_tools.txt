#############################################################################################
##part 1: pre-process  the sequences from metatranscriptomic and metagenomic dataset
for i in $(ls ./) ; do
    echo $i
    mv $i/Raw_Data/*.gz ./
done

splite_paired_seq(){
i=$1
base=$(basename "$i" .fastq.gz)
echo "Now processing the file ${base}"
if [ ! -f "${base}_R1.fastq.gz" ]; then
  echo "start to uncompress the file ${base}"
  pigz -d $i
  echo "Start to splite the forward and reverse sequence of file ${base}"
  cat $base.fastq | paste - - - - - - - - \
    | tee >(cut -f 1-4 | tr "\t" "\n" > ${base}_R1.fastq) \
    | cut -f 5-8 | tr "\t" "\n" > ${base}_R2.fastq
 fi
pigz $base.fastq  ${base}_R1.fastq ${base}_R2.fastq
echo "the processing of ${base} has been done"
}

export -f splite_paired_seq

time parallel -j 2 --eta --load 99% --noswap  splite_paired_seq ::: $(ls *.fastq.gz)





#quality control for the fastq sequences
##############################################################################################
fastqc rawdata/*.gz -t 20 -o fastqc_rawdata


for i in metagenome_data_raw/*_R1.fastq.gz; do
   basename=$(basename "$i" _R1.fastq.gz)
   echo $basename
   if [ ! -f metagenome_data_clean/${basename}_val_2.fq.gz ]; then
     trim_galore -q 25 --phred33 --stringency 3 --length 110 \
               --paired metagenome_data_raw/${basename}_R1.fastq.gz    metagenome_data_raw/${basename}_R2.fastq.gz \
               --gzip \
               --basename $basename \
               --cores 24 \
               -o metagenome_data_clean 
   else 
     echo "${base} has beed done"
   fi
done



#extract the rRNA sequences https://github.com/biocore/sortmerna
############################################################################################
mkdir metagenome_data_rRNA
extract_rRNA (){
  name=$1
  base=$(basename $name _val_1.fq.gz)
  if [ ! -f metagenome_data_rRNA/$base.rRNA_fwd.fq.gz ]; then
      mkdir metagenome_data_rRNA/$base
      echo "start to process ${base}" 
     sortmerna \
       --workdir metagenome_data_rRNA/$base \
       --ref /home/microbiome/tools/sortmerna/data/rRNA_databases/unite-fungi-its.fasta \
       --ref /home/microbiome/tools/sortmerna/data/rRNA_databases/SILVA_138.1_LSURef_NR99_tax_silva.fasta \
       --paired_out --out2  --zip-out \
       --reads metagenome_data_clean/${base}_val_1.fq.gz \
       --reads metagenome_data_clean/${base}_val_2.fq.gz \
       --fastx  --aligned metagenome_data_rRNA/$base/$base.rRNA \
       --threads 24
     echo "processing of ${base} is done"
   else
     echo "${base} has been anlyzed"
   fi
}

export -f extract_rRNA


nohup time parallel -j 2 --eta --load 100% --noswap  extract_rRNA ::: $(cat metagenome_data_clean/file_list) &



###########################################################################################】
#MicroFisher classification
mkdir metagenome_data_Fisher
for i in $(cat metagenome_data_clean/file_list); do
   base=$(basename $i _val_1.fq.gz)
   echo "start to process the file ${base}"
  if [ ! -d metagenome_data_Fisher/$base ]; then
   mkdir metagenome_data_Fisher/$base
   mv metagenome_data_clean/${base}_val_1.fq.gz  metagenome_data_Fisher/$base/${base}_R1.fastq.gz
   mv metagenome_data_clean/${base}_val_2.fq.gz  metagenome_data_Fisher/$base/${base}_R2.fastq.gz
   
   for length in 80 120 150; do
       MicroFisher search -vv --db ITS1  -w metagenome_data_Fisher/$base \
                   --prefix ${base} \
                   --min $length  --db_path /home/microbiome/data_storage/SATA2/Fisher_test/short_DBs/MicroFisher_DBs
                   
       MicroFisher search -vv --db ITS2  -w metagenome_data_Fisher/$base \
                   --prefix ${base} \
                   --min $length  --db_path /home/microbiome/data_storage/SATA2/Fisher_test/short_DBs/MicroFisher_DBs
                   
       MicroFisher search -vv --db LSU_D1  -w metagenome_data_Fisher/$base \
                   --prefix ${base} \
                   --min $length  --db_path /home/microbiome/data_storage/SATA2/Fisher_test/short_DBs/MicroFisher_DBs
                   
       MicroFisher search -vv --db LSU_D2  -w metagenome_data_Fisher/$base \
                   --prefix ${base} \
                   --min $length  --db_path /home/microbiome/data_storage/SATA2/Fisher_test/short_DBs/MicroFisher_DBs
    done
    mv  metagenome_data_Fisher/$base/${base}_R1.fastq.gz  metagenome_data_clean/${base}_val_1.fq.gz  
    mv  metagenome_data_Fisher/$base/${base}_R2.fastq.gz  metagenome_data_clean/${base}_val_2.fq.gz 
    echo "processing of ${base} has been done"
   else
    echo "${base} was analyzed"
   fi
 done










       MicroFisher combine \
                   -w metagenome_data_Fisher/$base \
                   --combine ${base}_dbITS1_report.tsv ${base}_dbITS2_report.tsv ${base}_LSU_D1_report.tsv ${base}_LSU_D1_report.tsv \
                   --mode weighted --min_overlap 2


MicroFisher search -vv --db ITS1_fisher  -w /home/microbiome/data_storage/SATA3/metagenome_data/metagenome_data_clean \
                   --prefix 12957.1.300262.ACATAGGC-GCCTATGT_val \
                   --min 120  --db_path /home/microbiome/data_storage/SATA2/Fisher_test/short_DBs/MicroFisher_DBs




MicroFisher search -vv  
  -w PATH_TO_WORKSPACE \
  --prefix example_ --min 120 \
  --centrifuge_path PATH_TO_CENTRIFUGE \
  --db_path PATH_TO_DATABASE --db LSU_D2 \







############################################################################################
##Part 2: fungal classification using metaphlan and kaiju
#https://github.com/biobakery/biobakery/wiki/metaphlan3
#https://github.com/biobakery/MetaPhlAn/wiki/MetaPhlAn-3.0
mkdir metagenome_data_metaphlan
workdir='/data_storage/SATA3/haihua/metagenome_data'
for i in $(cat $workdir/metagenome_data_clean/file_list); do
   base=$(basename $i _val_1.fq.gz)
   echo "start to process the file ${base}"
  if [ ! -f $workdir/metagenome_data_metaphlan/${base}_profiled_metagenome.txt ]; then
    metaphlan $workdir/metagenome_data_clean/${base}_val_1.fq.gz,$workdir/metagenome_data_clean/${base}_val_2.fq.gz \
          --bowtie2out $workdir/metagenome_data_metaphlan/${base}.bowtie2.bz2 \
          --nproc 24 --input_type fastq \
          --force --ignore_bacteria --ignore_archaea \
          -o $workdir/metagenome_data_metaphlan/${base}_profiled_metagenome.txt
    echo "processing of ${base} has been done"
   else
    echo "${base} was analyzed"
   fi
 done





#https://github.com/bioinformatics-centre/kaiju/blob/master/README.md
mkdir metagenome_data_kaiju
for i in $(cat metagenome_data_clean/file_list); do
   base=$(basename $i _val_1.fq.gz)
   echo "start to process the file ${base}"
  if [ ! -f metagenome_data_kaiju/${base}_kaiju.out ]; then
    kaiju -t database/kaiju/nodes.dmp -f database/kaiju/fungi/kaiju_db_fungi.fmi \
            -i metagenome_data_clean/${base}_val_1.fq.gz -j metagenome_data_clean/${base}_val_2.fq.gz  \
            -o metagenome_data_kaiju/${base}_kaiju.out -z 24
    kaiju2table -t database/kaiju/nodes.dmp \
                -n database/kaiju/names.dmp -r genus \
                -o metagenome_data_kaiju/${base}_kaiju_summary.tsv metagenome_data_kaiju/${base}_kaiju.out \
                -l superkingdom,phylum,class,order,family,genus,species 
    echo "processing of ${base} has been done"
   else
    echo "${base} was analyzed"
   fi
 done


###########################################################################################
#Part3:#eukdetect
eukdetect --mode runall --configfile configfile_for_metagenome.yml --cores 24
snakemake --snakefile rules/eukdetect.rules --configfile [config file] --cores [cores] runall



##########################################################################################
#part4：Kraken2 
#https://github.com/DerrickWood/kraken2/wiki/Manual
#https://github.com/bxlab/metaWRAP/issues/355
#with the fungi database downloading issue, refer 
#https://blog.csdn.net/weixin_52602016/article/details/120689897
#https://github.com/DerrickWood/kraken2/issues/508

kraken2-build --download-library "fungi" --threads 24 --db KRAKEN2_DB
#Then build the taxonomy from those libraries:
kraken2-build --download-taxonomy --db KRAKEN2_DB

#Then build the entire database:
kraken2-build --build --db KRAKEN2_DB --threads 24

mkdir metagenome_data_kraken2
workdir='/data_storage/SATA3/haihua/metagenome_data'
for i in $(cat $workdir/metagenome_data_clean/file_list); do
   base=$(basename $i _val_1.fq.gz)
   echo "start to process the file ${base}"
  if [ ! -f $workdir/metagenome_data_kraken2/${base}.profile.txt ]; then
  
  kraken2 --db   /home/microbiome/data_storage/SATA3/kraken2/KRAKEN2_DB \
        --paired \
        $workdir/metagenome_data_clean/${base}_val_1.fq.gz $workdir/metagenome_data_clean/${base}_val_2.fq.gz \
        --report  $workdir/metagenome_data_kraken2/${base}.report.tsv \
        --output  $workdir/metagenome_data_kraken2/${base}.profile.txt \
        --threads 24 --use-mpa-style -gzip-compressed 
        
    echo "processing of ${base} has been done"
  else
    echo "${base} was analyzed"
  fi
done





  
kraken2 --db /apps/users/user01/wanghhh/metagenomic/databases/kraken2 
             TXA_Control_N702.N502.R1_kneaddata_paired.fastq  
        --report ../kraken2_output/TXA_Control_N702.N502.R1_kneaddata_paired.fastq.report 
        --output ../kraken2_output/TXA_Control_N702.N502.R1_kneaddata_paired.fastq_profile 
        --unclassified-out ../kraken2_output/TXA_Control_N702.N502.R1_kneaddata_paired.fastq_unclassified.fastq 
        --classified-out ../kraken2_output/TXA_Control_N702.N502.R1_kneaddata_paired.fastq_classified.fastq 
        --threads 3 --use-mpa-style -gzip-compressed 

 kraken2 --paired --classified-out cseqs#.fq seqs_1.fq seqs_2.fq
 
  kraken2 --db   /home/microbiome/data_storage/SATA3/kraken2/KRAKEN2_DB \
          --paired \
        $workdir/metagenome_data_clean/${base}_val_1.fq.gz $workdir/metagenome_data_clean/${base}_val_2.fq.gz \
        --report  $workdir/metagenome_data_kraken2/${base}.report.tsv \
        --output  $workdir/metagenome_data_kraken2/${base}.profile.txt \
        --threads 24 --use-mpa-style -gzip-compressed 



###########################################################################################
#Part4: MicroFfisher

MicroFisher_DBs=/home/microbiome/data_storage/SATA2/Fisher_test/short_DBs/MicroFisher_DBs

for i in cleandata/*_R1.fastq.gz; do
    basename=$(basename  "$i" _R1.fastq.gz)
    echo $basename
    mkdir MicroFisher/${basename}_microfisher
    cp cleandata/${basename}_* MicroFisher/${basename}_microfisher
    
    for DB_cat in  ITS1 ITS2 LsuD1 LsuD2 ; do
                   if [ "$DB_cat" = "ITS1" ]; then
                       DB=ITS1_fisher
                     elif [ "$DB_cat" = "ITS2" ]; then
                       DB=ITS2_fisher
                     elif [ "$DB_cat" = "LsuD1" ]; then
                       DB=LSU_D1_fisher_new
                     elif [ "$DB_cat" = "LsuD2" ]; then
                       DB=LSU_D2_fisher_new
                    fi
                   echo $DB
                   python /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/MicroFisher.py  search -vv  \
                               -w MicroFisher/${basename}_microfisher  \
                               --db_path $MicroFisher_DBs \
                               --prefix $basename \
                               --min 120 --db $DB
      done
      
      
      cd MicroFisher/${basename}_microfisher
      python  /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/run_merge_reports.py  \
                    --combine result_${basename}_min120_dbITS1_fisher_report.tsv \
                              result_${basename}_min120_dbITS2_fisher_report.tsv \
                    --mode weighted
      for i in merged_output_*.tsv ; do
          name=$(basename $i .tsv)
          mv $i ${name}.ITS.min120.txt
      done
             
      python  /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/run_merge_reports.py  \
                    --combine result_${basename}_min120_dbLSU_D1_fisher_new_report.tsv \
                              result_${basename}_min120_dbLSU_D2_fisher_new_report.tsv \
                    --mode weighted
       for i in merged_output_*.tsv ; do
          name=$(basename $i .tsv)
          mv $i ${name}.LSU.min120.txt
      done
                   
      python  /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/run_merge_reports.py  \
                    --combine result_${basename}_min120_dbLSU_D1_fisher_new_report.tsv \
                              result_${basename}_min120_dbLSU_D2_fisher_new_report.tsv \
                              result_${basename}_min120_dbITS1_fisher_report.tsv \
                              result_${basename}_min120_dbITS2_fisher_report.tsv \
                    --mode weighted
       for i in merged_output_*.tsv ; do
          name=$(basename $i .tsv)
          mv $i ${name}.ITS_LSU.min120.txt
      done
      
      cd /home/microbiome/data_storage/SATA2/metagenome_data/
      
      
      
      
      for DB_cat in  ITS1 ITS2 LsuD1 LsuD2 ; do
                   if [ "$DB_cat" = "ITS1" ]; then
                       DB=ITS1_fisher
                     elif [ "$DB_cat" = "ITS2" ]; then
                       DB=ITS2_fisher
                     elif [ "$DB_cat" = "LsuD1" ]; then
                       DB=LSU_D1_fisher_new
                     elif [ "$DB_cat" = "LsuD2" ]; then
                       DB=LSU_D2_fisher_new
                    fi
                   echo $DB
                   python /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/MicroFisher.py  search -vv  \
                               -w MicroFisher/${basename}_microfisher  \
                               --db_path $MicroFisher_DBs \
                               --prefix $basename \
                               --min 80 --db $DB
      done
      
      
      cd MicroFisher/${basename}_microfisher
      python  /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/run_merge_reports.py  \
                    --combine result_${basename}_min80_dbITS1_fisher_report.tsv \
                              result_${basename}_min80_dbITS2_fisher_report.tsv \
                    --mode weighted
      for i in merged_output_*.tsv ; do
          name=$(basename $i .tsv)
          mv $i ${name}.ITS.min80.txt
      done
             
      python  /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/run_merge_reports.py  \
                    --combine result_${basename}_min80_dbLSU_D1_fisher_new_report.tsv \
                              result_${basename}_min80_dbLSU_D2_fisher_new_report.tsv \
                    --mode weighted
       for i in merged_output_*.tsv ; do
          name=$(basename $i .tsv)
          mv $i ${name}.LSU.min80.txt
      done
                   
      python  /home/microbiome/data_storage/SATA2/Fisher_test/MicroFisher/MicroFisher-Fungal-Profiling/python/run_merge_reports.py  \
                    --combine result_${basename}_min80_dbLSU_D1_fisher_new_report.tsv \
                              result_${basename}_min80_dbLSU_D2_fisher_new_report.tsv \
                              result_${basename}_min80_dbITS1_fisher_report.tsv \
                              result_${basename}_min80_dbITS2_fisher_report.tsv \
                    --mode weighted
       for i in merged_output_*.tsv ; do
          name=$(basename $i .tsv)
          mv $i ${name}.ITS_LSU.min80.txt
      done
      
      cd /home/microbiome/data_storage/SATA2/metagenome_data/
done








###########################################################################################
#Part3: denovo assembly approach
for i in cleandata/*_R1_val_1.fq.gz; do
    basename=$(basename  "$i" _R1_val_1.fq.gz)
    echo $basename
    bowtie2 -x database/assemble/D1D2_ref -p 24 \
            -1 cleandata/${basename}_R1_val_1.fq.gz \
            -2 cleandata/${basename}_R2_val_2.fq.gz \
            -S deNovoAssemble/${basename}.sam \
            --al-conc-gz deNovoAssemble/${basename}_aligned.gz
    rm -f deNovoAssemble/${basename}.sam
done
    
    
    
    
    
    
    
    
    
